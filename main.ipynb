{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudh-cp/ISODS-NLP/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GLgdMbOvIUj"
      },
      "source": [
        "## **The International Society of Data Scientists - NLP Track**\n",
        "#### **Fashion and Beauty Review Rating - The 3rd Annual International Data Science & AI Competition 2022**\n",
        "\n",
        "\n",
        "Predict how satisfied customers are based on their product reviews, to help with insight in fashion and beauty products."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJSNi-95vIUp"
      },
      "source": [
        "#### Downloading Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuZaInryvIUp"
      },
      "outputs": [],
      "source": [
        "%pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l41uu4prvIUq",
        "outputId": "d89ce016-93fb-4c06-de69-50a224d46f8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username:Your Kaggle Key:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\cpani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cryptography\\hazmat\\backends\\openssl\\x509.py:14: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading fashion-and-beauty-reviews.zip to .\\fashion-and-beauty-reviews\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 112M/112M [00:28<00:00, 4.15MB/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting archive .\\fashion-and-beauty-reviews/fashion-and-beauty-reviews.zip to .\\fashion-and-beauty-reviews\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/competitions/fashion-and-beauty-reviews\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSq4AlzHvIUs"
      },
      "source": [
        "#### Working with the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeowAjlrvIUs"
      },
      "outputs": [],
      "source": [
        "%pip install pandas\n",
        "%pip install numpy\n",
        "%pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLEeDXHkvIUt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KWskdrYvIUt"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv(r\"fashion-and-beauty-reviews\\review_train.tsv\", sep='\\t', header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9zHdgXOvIUu",
        "outputId": "a2e844dd-9904-42b7-e211-5ad5013dcd24"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>summary</th>\n",
              "      <th>product</th>\n",
              "      <th>reviewer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>I received this cream about 8 days ago and hav...</td>\n",
              "      <td>Thought this cream was making me sick...</td>\n",
              "      <td>B00DKEQYJY</td>\n",
              "      <td>A3IQA3VVDHGAK1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Beautiful pieces</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>B00L4JJKH0</td>\n",
              "      <td>A1QWCVZMSYG1N2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Really impressive tree. It goes together quick...</td>\n",
              "      <td>Highly recommended</td>\n",
              "      <td>1620213982</td>\n",
              "      <td>A2QRLRHMFDJ25E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>good</td>\n",
              "      <td>Four Stars</td>\n",
              "      <td>B01D2J35BG</td>\n",
              "      <td>A2MMO1P2ZNEUNF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Gift for granddaughter.  She loved it.</td>\n",
              "      <td>Cool looking umbrella.</td>\n",
              "      <td>B01422IQD4</td>\n",
              "      <td>A1WXKDA47VPOFT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review  \\\n",
              "0     4.0  I received this cream about 8 days ago and hav...   \n",
              "1     5.0                                   Beautiful pieces   \n",
              "2     5.0  Really impressive tree. It goes together quick...   \n",
              "3     4.0                                               good   \n",
              "4     5.0             Gift for granddaughter.  She loved it.   \n",
              "\n",
              "                                    summary     product        reviewer  \n",
              "0  Thought this cream was making me sick...  B00DKEQYJY  A3IQA3VVDHGAK1  \n",
              "1                                Five Stars  B00L4JJKH0  A1QWCVZMSYG1N2  \n",
              "2                        Highly recommended  1620213982  A2QRLRHMFDJ25E  \n",
              "3                                Four Stars  B01D2J35BG  A2MMO1P2ZNEUNF  \n",
              "4                    Cool looking umbrella.  B01422IQD4  A1WXKDA47VPOFT  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxWz5LNQvIUv"
      },
      "source": [
        "##### Simple Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcslstlIvIUv",
        "outputId": "5a8ff54c-3bfd-4bc0-f01b-e3aecce77394"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1003984, 5)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR4AwMh-vIUw",
        "outputId": "e7316505-e119-4ecc-e9d2-39b72694f487"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Possible ratings : [1. 2. 3. 4. 5.]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Possible ratings : {np.sort(dataframe['rating'].unique())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPa7CSQ7vIUw",
        "outputId": "fb9d029e-b49b-40fe-a73e-e046c2876c8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longest string in 'review' is record# 788873 of length 13741\n",
            "Shortest string in 'review' is record# 9398 of length 1\n",
            "Longest string in 'summary' is record# 800077 of length 267\n",
            "Shortest string in 'summary' is record# 2321 of length 1\n"
          ]
        }
      ],
      "source": [
        "for col in ['review', 'summary']:\n",
        "      print(f\"Longest string in '{col}' is record# {dataframe[col].str.len().argmax()} \"\n",
        "            f\"of length {len(dataframe.iloc[dataframe[col].str.len().argmax()][col])}\")\n",
        "\n",
        "      print(f\"Shortest string in '{col}' is record# {dataframe[col].str.len().argmin()} \"\n",
        "            f\"of length {len(dataframe.iloc[dataframe[col].str.len().argmin()][col])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7V1X9bKDvIUx",
        "outputId": "884167a9-5368-4945-9c32-d4347a6f4565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rating         0\n",
              "review      1304\n",
              "summary      597\n",
              "product        0\n",
              "reviewer       0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrN0Uc_4vIUx"
      },
      "source": [
        "#### Set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5HqXLM7vIUy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "LEARN_RT = 0.001\n",
        "PATIENCE = 5\n",
        "\n",
        "OPTIMIZER = torch.optim.Adam\n",
        "SCHEDULER = torch.optim.lr_scheduler.ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "g5SvA22gv9PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/ISODS/\""
      ],
      "metadata": {
        "id": "M9gsOkOpn70f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORHas1EdvIUy"
      },
      "outputs": [],
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHg0LVTmvIUy"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "set_seeds(seed=int(time.time()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fulZcWohvIUz",
        "outputId": "3fad3f67-36a0-48b3-dab1-7420ff1f5c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device(\"cuda\" if (\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "print (device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_i_BJ6TvIUz"
      },
      "source": [
        "#### Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrmOP7QXvIUz"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv(r\"fashion-and-beauty-reviews\\review_train.tsv\", sep='\\t', header=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J4p95EhvIU0"
      },
      "outputs": [],
      "source": [
        "# Randomize/Shuffle order of all records in the dataset\n",
        "dataframe = dataframe.sample(frac=1).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQzZNm39vIU0",
        "outputId": "738da1c2-ccba-4d96-e4e9-6968ecfbbfd4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review</th>\n",
              "      <th>summary</th>\n",
              "      <th>product</th>\n",
              "      <th>reviewer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>fabric is easy care.  am 5'3.  hits me about 2...</td>\n",
              "      <td>great flip skirt for ballroom dancing</td>\n",
              "      <td>B00GN72LYC</td>\n",
              "      <td>A26ZA7I89DN029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>B00UAWE978</td>\n",
              "      <td>A3P3UITN9EQIW4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Got this for my mom. She loved it. It is reall...</td>\n",
              "      <td>She loved it. It is really cute</td>\n",
              "      <td>B00OB8WRBW</td>\n",
              "      <td>A226AVPBKYZUU0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Great product.  Great seller</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>B00FGCU5M0</td>\n",
              "      <td>A2JL10RY5CI9AM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>I love this necklace. It's so pretty and looks...</td>\n",
              "      <td>I love this necklace</td>\n",
              "      <td>B01ADTLECK</td>\n",
              "      <td>A2TPTTT3JVFJL6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                             review  \\\n",
              "0     5.0  fabric is easy care.  am 5'3.  hits me about 2...   \n",
              "1     5.0                                                NaN   \n",
              "2     5.0  Got this for my mom. She loved it. It is reall...   \n",
              "3     5.0                       Great product.  Great seller   \n",
              "4     5.0  I love this necklace. It's so pretty and looks...   \n",
              "\n",
              "                                 summary     product        reviewer  \n",
              "0  great flip skirt for ballroom dancing  B00GN72LYC  A26ZA7I89DN029  \n",
              "1                             Five Stars  B00UAWE978  A3P3UITN9EQIW4  \n",
              "2        She loved it. It is really cute  B00OB8WRBW  A226AVPBKYZUU0  \n",
              "3                             Five Stars  B00FGCU5M0  A2JL10RY5CI9AM  \n",
              "4                   I love this necklace  B01ADTLECK  A2TPTTT3JVFJL6  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iisTcSEcvIU0",
        "outputId": "08723d03-b579-41a4-c8c1-d0da7971c73e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rating    0\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove product and reviewer information and combine review and summary into one column\n",
        "dataframe.drop(['product', 'reviewer'], axis=1, inplace=True)\n",
        "dataframe['text'] = dataframe['summary'] + ' ' +dataframe['review']\n",
        "dataframe.drop(['review', 'summary'], axis=1, inplace=True)\n",
        "\n",
        "dataframe.dropna(inplace=True)\n",
        "dataframe.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsDlNTaSvIU1",
        "outputId": "32755067-f49b-4096-ef39-c9337a89b7ff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>great flip skirt for ballroom dancing fabric i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>She loved it. It is really cute Got this for m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Five Stars Great product.  Great seller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>I love this necklace I love this necklace. It'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Worthy the money Nice jeans, true to size. I w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                               text\n",
              "0     5.0  great flip skirt for ballroom dancing fabric i...\n",
              "2     5.0  She loved it. It is really cute Got this for m...\n",
              "3     5.0            Five Stars Great product.  Great seller\n",
              "4     5.0  I love this necklace I love this necklace. It'...\n",
              "5     5.0  Worthy the money Nice jeans, true to size. I w..."
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eeAnYfrvIU1"
      },
      "outputs": [],
      "source": [
        "%pip install contractions\n",
        "%pip install nltk\n",
        "%pip install inflect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Heu2cNJDvIU1",
        "outputId": "86b4eac1-dfc4-4c07-c7f7-a6b86f423e93"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\cpani\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\cpani\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\cpani\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\cpani\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import contractions\n",
        "import inflect\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "stop_words = set(stopwords.words('english')) - {'against', 'few', 'more', 'no', 'nor', 'not', 'very'}\n",
        "lemma = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Y7OjRc1vIU2"
      },
      "outputs": [],
      "source": [
        "def process(text):\n",
        "\n",
        "   text = re.sub(r'http\\S+', '', text)             # Remove links\n",
        "   text = re.sub(r\"\\([^)]*\\)\", \"\", text)           # Remove word within brackets\n",
        "   text = re.sub(f'[{punctuation}]', '', text)     # Remove punctuation\n",
        "      \n",
        "   # If number and word are combined seperate with space\n",
        "   text = re.sub(r'(\\d*)(\\D+)(\\d*)', r'\\1 \\2 \\3', text)\n",
        "   \n",
        "   text = re.sub(\" +\", \" \", text)                  # Remove multiple spacing\n",
        "   text = text.strip()\n",
        "   \n",
        "   text = text.lower()                             # Convert to lowercase\n",
        "   text = contractions.fix(text)                   # Contraction replacement\n",
        "   \n",
        "   tokens = nltk.word_tokenize(text)               # Tokenize\n",
        "   \n",
        "   # Convert all numbeers to words\n",
        "   for index, token in enumerate(tokens):\n",
        "      if token.isdigit():\n",
        "         try:\n",
        "            tokens[index] = inflect.engine().number_to_words(token)\n",
        "         except Exception:\n",
        "            print(token)\n",
        "            \n",
        "   # Remove stopwords\n",
        "   tokens = [token for token in tokens if token not in stop_words]\n",
        "   \n",
        "   # Lemmatization\n",
        "   tokens = [lemma.lemmatize(token, pos='v') for token in tokens]\n",
        "   \n",
        "   text = ' '.join(tokens)\n",
        "   \n",
        "   return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp_mHLjQvIU2",
        "outputId": "17bc614c-20ae-420b-aace-c708fd740c88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7791793621055041073741832752334614789979\n",
            "4666286801020021073741825353887201376151820146361416897\n"
          ]
        }
      ],
      "source": [
        "dataframe['text'] = dataframe['text'].apply(process)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwJ4oDdbvIU4"
      },
      "outputs": [],
      "source": [
        "dataframe.to_csv(r\"fashion-and-beauty-reviews\\review_train_processed.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkvvjcFGvIU6"
      },
      "source": [
        "#### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jeAewM_vIU6",
        "outputId": "428563e0-3614-4e11-dd5e-98e65cf7e497",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rating    float64\n",
              "text       object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "dataframe.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DavnZiCfvIU6"
      },
      "source": [
        "The point of label encoding is to convert any labels assigned to the output classes to an integer value. However, since this dataset has the output values as numbers already we can convert them to int from float."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJSDFFiMvIU6"
      },
      "outputs": [],
      "source": [
        "dataframe['rating'] = dataframe['rating'].astype(np.int64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe['rating'] = dataframe['rating'] - 1"
      ],
      "metadata": {
        "id": "B-ytlZlFx3Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Possible ratings : {np.sort(dataframe['rating'].unique())}\")"
      ],
      "metadata": {
        "id": "0a58L3UsyGmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4lc_GHLvIU7",
        "outputId": "b00b31e8-db6b-4bbf-db14-f2d44a0312f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rating     int64\n",
              "text      object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "dataframe.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26_sNjTLvIU4"
      },
      "source": [
        "#### Data Split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_csv(BASE_PATH + r\"fashion-and-beauty-reviews/review_train_processed.tsv\", sep='\\t', header=0, index_col=0)"
      ],
      "metadata": {
        "id": "KQlPKMFixGlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGgAAG4lvIU4"
      },
      "outputs": [],
      "source": [
        "dataframe = pd.read_csv(r\"fashion-and-beauty-reviews\\review_train_processed.tsv\", sep='\\t', header=0, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUt-sJnUvIU5",
        "outputId": "ebe604cd-47a1-452e-a4c1-c98c6123bcc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rating    0\n",
              "text      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "dataframe.dropna(inplace=True)\n",
        "dataframe.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrUoVWgGvIU5"
      },
      "outputs": [],
      "source": [
        "%pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2ksyFjgvIU5"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9Y7JN0lvIU5"
      },
      "outputs": [],
      "source": [
        "# Configure for 80% data to be for training and the rest for validation here.\n",
        "\n",
        "TRAIN_SIZE = 0.8\n",
        "VAL_SIZE = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPhLDwOBvIU5"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "X = dataframe['text'].values\n",
        "y = dataframe['rating'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25UPaPk9vIU6"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPn6mnnKvIU6",
        "outputId": "18aee7dd-d1f5-4fa1-fc77-720192d2c363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (801651,), y_train: (801651,)\n",
            "X_val: (200413,), y_val: (200413,)\n"
          ]
        }
      ],
      "source": [
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGNMlEgjvIU7"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYJ11mFqvIU7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgEdCwLmvIU7"
      },
      "outputs": [],
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None,\n",
        "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = \"\" if self.char_level else \" \"\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(\" \")\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {\n",
        "                \"char_level\": self.char_level,\n",
        "                \"oov_token\": self.oov_token,\n",
        "                \"token_to_index\": self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xuvfSSDvIU8",
        "outputId": "8a0342c6-0984-4558-a073-b0d8b4ae2219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Tokenizer(num_tokens=500)>\n"
          ]
        }
      ],
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=500)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fycJkkpVvIU8"
      },
      "outputs": [],
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-_aV101vIU8",
        "outputId": "a57cd315-e275-44cf-8ec2-388188554655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PAD>\n",
            "<UNK>\n",
            "not\n",
            "star\n",
            "love\n",
            "least freq token's freq: 4955\n"
          ]
        }
      ],
      "source": [
        "# Sample of tokens\n",
        "for index in range(5):\n",
        "    print(tokenizer.index_to_token[index])\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKOijr-OvIU8"
      },
      "source": [
        "#### Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataloader is responsible for the loading of data in the form of batches to the CNN model. Since the one-hot encoding cannot be performed over the entirity of the dataset, we will perform one-hot encoding and padding over a batch instead."
      ],
      "metadata": {
        "id": "ZosvmztEt-d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### One-hot encoding"
      ],
      "metadata": {
        "id": "X90n1ZkXuYE7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "429rCvOIvIU8"
      },
      "outputs": [],
      "source": [
        "def to_categorical(seq, num_classes):\n",
        "    \"\"\"One-hot encode a sequence of tokens.\"\"\"\n",
        "    one_hot = np.zeros((len(seq), num_classes))\n",
        "    for i, item in enumerate(seq):\n",
        "        one_hot[i, item] = 1.\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Padding"
      ],
      "metadata": {
        "id": "V39GP2LtuiJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    num_classes = sequences[0].shape[-1]\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len, num_classes))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences"
      ],
      "metadata": {
        "id": "kpZeSkJnukSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Dataloader"
      ],
      "metadata": {
        "id": "BawAXKNwu80T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILTER_SIZE = 1 # unigram"
      ],
      "metadata": {
        "id": "I-aF8LTPvHui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch)\n",
        "        X = batch[:, 0]\n",
        "        y = batch[:, 1]\n",
        "\n",
        "        # Perform one-hot encoding\n",
        "        X = [to_categorical(seq, num_classes=VOCAB_SIZE) for seq in X]\n",
        "\n",
        "        # Pad sequences\n",
        "        X = pad_sequences(X, max_seq_len=self.max_filter_size)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.FloatTensor(X.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "CyZ1Mlg3vAfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=FILTER_SIZE)\n",
        "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=FILTER_SIZE)"
      ],
      "metadata": {
        "id": "2_hXRjevvsU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = train_dataset.create_dataloader(batch_size=BATCH_SIZE)\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "XO7tSWw7vub7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "B2qOJkJjwaTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLBase(nn.Module):\n",
        "    \n",
        "    def accuracy(self, outputs, labels):\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = self.accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n"
      ],
      "metadata": {
        "id": "6EjyPnixy_bV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "NUM_FILTERS = OUT_CHANNELS = 50\n",
        "STRIDE = 1\n",
        "FILTER_SIZE = 1\n",
        "HIDDEN_DIM = 100\n",
        "DROPOUT_P = 0.1\n",
        "NUM_CLASSES = 5"
      ],
      "metadata": {
        "id": "73RBsB-t6Tdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(MLBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.filter_size = FILTER_SIZE\n",
        "        self.conv = nn.Conv1d(\n",
        "            in_channels=VOCAB_SIZE, out_channels=OUT_CHANNELS,\n",
        "            kernel_size=FILTER_SIZE, stride=1, padding=0, padding_mode=\"zeros\")\n",
        "        \n",
        "        self.bn1 = nn.BatchNorm1d(num_features=OUT_CHANNELS)\n",
        "\n",
        "        # FC layers\n",
        "        self.fc1 = nn.Linear(NUM_FILTERS, HIDDEN_DIM)\n",
        "        self.dropout = nn.Dropout(DROPOUT_P)\n",
        "        self.fc2 = nn.Linear(HIDDEN_DIM, NUM_CLASSES)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "\n",
        "        x_in = xb.transpose(1, 2)\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\n",
        "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\n",
        "\n",
        "        # Conv outputs\n",
        "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\n",
        "        z = F.relu(self.bn1(z))\n",
        "        z = F.max_pool1d(z, z.size(2)).squeeze(2)\n",
        "\n",
        "        # FC layer\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "        return z"
      ],
      "metadata": {
        "id": "UHIv_cWYzDJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()"
      ],
      "metadata": {
        "id": "dnnnydVH1a-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Optimizer and Scheduler"
      ],
      "metadata": {
        "id": "oWFD-qhk1nYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = OPTIMIZER(model.parameters(), lr=LEARN_RT)\n",
        "scheduler = SCHEDULER(optimizer, mode=\"min\", factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "Xs_--JmL1l78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "EfQNikjVzUf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "x5XM7cEW2o1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n"
      ],
      "metadata": {
        "id": "oCjSanQgzM2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, train_loader, val_loader, optimizer, scheduler, patienceInit):\n",
        "    history = []\n",
        "    best_val_loss = np.inf\n",
        "    patience = patienceInit\n",
        "    \n",
        "    for epoch in range(EPOCHS):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        \n",
        "        # Change learning rate if required\n",
        "        scheduler.step(result['val_loss'])\n",
        "        \n",
        "        # Early stopping\n",
        "        if result['val_loss'] < best_val_loss:\n",
        "            best_val_loss = result['val_loss']\n",
        "            best_model = model\n",
        "            patience = patienceInit  # reset _patience\n",
        "        else:\n",
        "            patience -= 1\n",
        "        \n",
        "        # Save model after each epoch\n",
        "        torch.save(model.state_dict(), BASE_PATH + f'Models/{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}_{result[\"val_acc\"]}_{epoch}.pth')\n",
        "\n",
        "        # Logging\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['epoch'] = epoch\n",
        "        result['lr'] = optimizer.param_groups[0]['lr']\n",
        "        result['patience'] = patience\n",
        "        \n",
        "        # model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "        \n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {result['train_loss']:.5f}, \"\n",
        "            f\"val_loss: {result['val_loss']:.5f}, \"\n",
        "            f\"val_acc: { result['val_acc']:.5f}, \"\n",
        "            f\"lr: {optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "            f\"patience: {patience}\"\n",
        "        )\n",
        "        \n",
        "        if not patience:  # 0\n",
        "            print(\"Stopping early!\")\n",
        "            break\n",
        "    \n",
        "    return history\n"
      ],
      "metadata": {
        "id": "rqPiPG1D1Nx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(model, train_dataloader, val_dataloader, optimizer, scheduler, PATIENCE)"
      ],
      "metadata": {
        "id": "bTEmaxwn1Xh0",
        "outputId": "bfde568d-0338-441a-a986-8c2503ab7fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-7eceb50dceaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATIENCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-47cbd1678265>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, optimizer, scheduler, patienceInit)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-2aa764246d48>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2995\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target 5 is out of bounds."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation"
      ],
      "metadata": {
        "id": "v2sBkkbP11Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "2vvSf0x_ruJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs')\n",
        "    plt.savefig(BASE_PATH + f'Analysis/{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}_Accuracy_vs_Epoch.png')\n",
        "    # plt.show()"
      ],
      "metadata": {
        "id": "6DH6cw0Irksw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs')\n",
        "    plt.savefig(BASE_PATH + f'Analysis/{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}_Loss_vs_Epoch.png')\n",
        "    # plt.show()"
      ],
      "metadata": {
        "id": "HuXHBVnQrlaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)\n",
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "fVnJc75710vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'Analysis/{datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}_History.json', 'w', encoding ='utf8') as json_file:\n",
        "  json.dump(history, json_file, ensure_ascii = True, indent=4)\n"
      ],
      "metadata": {
        "id": "yiUwcElP19Sy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7f2c6d96787cba19ceb301b0ff1d01f982e1c2f8b515f24385efde571fabf7c9"
      }
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}